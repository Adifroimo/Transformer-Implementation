# Transformer-Implementation
In this project I implemented a Transformer model for English to French machine translation, incorporating encoder-decoder architecture with attention mechanisms.<br> Two attention mechanisms, dot-product attention and masked softmax attention, are implemented.
